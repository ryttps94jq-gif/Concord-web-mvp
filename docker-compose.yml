services:
  # Backend API Server — GPU Pod: 16 vCPU / 62GB RAM / RTX 4000 Ada 20GB VRAM
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: concord-backend
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    read_only: false  # Data dir needs writes; consider tmpfs for /tmp
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
    environment:
      - NODE_ENV=production
      - PORT=5050
      - DATA_DIR=/data
      - DB_PATH=/data/db/concord.db
      - STATE_PATH=/data/concord_state.json
      - NODE_OPTIONS=--max-old-space-size=8192
      - UV_THREADPOOL_SIZE=8
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama-conscious:11434}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-https://concord-os.org}
      - FRONTEND_URL=${FRONTEND_URL:-https://concord-os.org}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - SHUTDOWN_TIMEOUT_MS=${SHUTDOWN_TIMEOUT_MS:-10000}
      - CONCORD_WS_ENABLED=${CONCORD_WS_ENABLED:-true}
      # Four-Brain Cognitive Architecture
      - BRAIN_CONSCIOUS_URL=${BRAIN_CONSCIOUS_URL:-http://ollama-conscious:11434}
      - BRAIN_CONSCIOUS_MODEL=${BRAIN_CONSCIOUS_MODEL:-qwen2.5:14b-q4_K_M}
      - BRAIN_SUBCONSCIOUS_URL=${BRAIN_SUBCONSCIOUS_URL:-http://ollama-subconscious:11434}
      - BRAIN_SUBCONSCIOUS_MODEL=${BRAIN_SUBCONSCIOUS_MODEL:-qwen2.5:7b}
      - BRAIN_UTILITY_URL=${BRAIN_UTILITY_URL:-http://ollama-utility:11434}
      - BRAIN_UTILITY_MODEL=${BRAIN_UTILITY_MODEL:-qwen2.5:3b}
      - BRAIN_REPAIR_URL=${BRAIN_REPAIR_URL:-http://ollama-repair:11434}
      - BRAIN_REPAIR_MODEL=${BRAIN_REPAIR_MODEL:-qwen2.5:1.5b}
      # Auth — MUST set these in .env file
      - JWT_SECRET=${JWT_SECRET}
      - SESSION_SECRET=${SESSION_SECRET:-}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - AUTH_MODE=${AUTH_MODE:-hybrid}
      - AUTH_ENABLED=${AUTH_ENABLED:-true}
      - SOVEREIGN_USERNAME=${SOVEREIGN_USERNAME:-Concord_Founder_Dutch}
      - FOUNDER_SECRET=${FOUNDER_SECRET:-}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN:-7d}
      - REFRESH_TOKEN_EXPIRES=${REFRESH_TOKEN_EXPIRES:-30d}
      - BCRYPT_ROUNDS=${BCRYPT_ROUNDS:-12}
      - ALLOW_REGISTRATION=${ALLOW_REGISTRATION:-true}
      # LLM — set OPENAI_API_KEY in .env for AI features
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL_FAST=${OPENAI_MODEL_FAST:-gpt-4o-mini}
      - OPENAI_MODEL_SMART=${OPENAI_MODEL_SMART:-gpt-4.1}
      # Stripe — set these in .env to enable payments
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET:-}
      - STRIPE_PRICE_PRO=${STRIPE_PRICE_PRO:-}
      - STRIPE_PRICE_TEAMS=${STRIPE_PRICE_TEAMS:-}
      # Optional features
      - EMBEDDINGS_ENABLED=${EMBEDDINGS_ENABLED:-true}
      - FEDERATION_ENABLED=${FEDERATION_ENABLED:-false}
      # Safety — disabled by default in production
      - ENABLE_TERMINAL_EXEC=${ENABLE_TERMINAL_EXEC:-false}
      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-false}
    depends_on:
      ollama-conscious:
        condition: service_healthy
      ollama-subconscious:
        condition: service_healthy
      ollama-utility:
        condition: service_healthy
      ollama-repair:
        condition: service_healthy
    volumes:
      - concord-data:/data
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5050/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s  # 3 min grace for embedding load + Ollama warm-up
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 4G
          cpus: '2.0'

  # Frontend Next.js App
  frontend:
    build:
      context: ./concord-frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-https://concord-os.org}
        - NEXT_PUBLIC_SOCKET_URL=${NEXT_PUBLIC_SOCKET_URL:-https://concord-os.org}
        - NEXT_PUBLIC_SITE_URL=${NEXT_PUBLIC_SITE_URL:-https://concord-os.org}
    container_name: concord-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - frontend-data:/data
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: concord-nginx
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - frontend
      - backend
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:80/ready || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"

  # Certbot for SSL certificates
  certbot:
    image: certbot/certbot
    container_name: concord-certbot
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    entrypoint: |
      /bin/sh -c '
      trap exit TERM
      while :; do
        certbot renew --quiet --non-interactive 2>&1 | tee -a /var/log/certbot.log || echo "[Certbot] Renewal check completed with warnings at $$(date)"
        sleep 12h & wait
      done
      '
    healthcheck:
      test: ["CMD", "test", "-f", "/etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh", "-o", "-d", "/etc/letsencrypt/live"]
      interval: 86400s
      timeout: 10s
      retries: 1
      start_period: 60s

  # Prometheus — scrapes /metrics from backend
  prometheus:
    image: prom/prometheus:latest
    container_name: concord-prometheus
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
      - "--web.enable-lifecycle"
    networks:
      - concord-network
    depends_on:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  # Grafana — dashboards for Concord metrics
  grafana:
    image: grafana/grafana:latest
    container_name: concord-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:?GRAFANA_USER must be set in .env}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:?GRAFANA_PASSWORD must be set in .env}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    # Bind Grafana to localhost only — access via SSH tunnel or VPN in production
    ports:
      - "127.0.0.1:3001:3000"
    networks:
      - concord-network
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.15'

  # Qdrant — vector search engine for embedding similarity
  qdrant:
    image: qdrant/qdrant:latest
    container_name: concord-qdrant
    restart: unless-stopped
    environment:
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=2
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:6333/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # ── Four-Brain Cognitive Architecture (GPU: RTX 4000 Ada, 16GB VRAM shared) ──
  # VRAM budget: 14B-q4(~5.5GB) + 7B(~4.5GB) + 3B(~2GB) + 1.5B(~1GB) + embed(~0.3GB) = ~13.3GB → 2.7GB headroom
  # Brain 1: Conscious — chat and deep reasoning (14B-q4_K_M on GPU, ~5.5GB VRAM)
  ollama-conscious:
    image: ollama/ollama
    container_name: concord-ollama-conscious
    restart: unless-stopped
    environment:
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ollama-conscious-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 10G
          cpus: '4.0'
        reservations:
          memory: 6G
          cpus: '2.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Brain 2: Subconscious — autogen, dream, evolution, synthesis, birth (7B on GPU, ~4.5GB VRAM)
  # THE big win: 1.5B → 7B means every DTU Concord creates is fundamentally smarter
  ollama-subconscious:
    image: ollama/ollama
    container_name: concord-ollama-subconscious
    restart: unless-stopped
    environment:
      - OLLAMA_NUM_PARALLEL=6
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ollama-subconscious-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '1.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Brain 3: Utility — lens interactions, entity actions, quick domain tasks (3B on GPU, ~2GB VRAM)
  # Speed matters more than depth here — 3B stays the same, fast turnaround
  ollama-utility:
    image: ollama/ollama
    container_name: concord-ollama-utility
    restart: unless-stopped
    environment:
      - OLLAMA_NUM_PARALLEL=8
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ollama-utility-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '4.0'
        reservations:
          memory: 2G
          cpus: '1.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Brain 4: Repair — error detection, auto-fix (1.5B on GPU, ~1GB VRAM)
  # 3x upgrade from 0.5B — can actually parse error messages now
  ollama-repair:
    image: ollama/ollama
    container_name: concord-ollama-repair
    restart: unless-stopped
    environment:
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ollama-repair-data:/root/.ollama
    networks:
      - concord-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  concord-network:
    driver: bridge

volumes:
  concord-data:
    driver: local
  qdrant-data:
    driver: local
  ollama-conscious-data:
    driver: local
  ollama-subconscious-data:
    driver: local
  ollama-utility-data:
    driver: local
  ollama-repair-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  frontend-data:
    driver: local
